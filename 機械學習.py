# -*- coding: utf-8 -*-
"""機械學習

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16iDc9Bft-SYGwoxJz7wvykGsxfAD2gQI
"""

from google.colab import drive
drive.mount('/content/drive')

#導入環境
import pandas as pd
import numpy as np
import os
import tensorflow as tf
from matplotlib import pyplot as plt

from keras.models import Sequential
from keras.models import load_model
from keras.layers import * #引入層數
from keras.callbacks import TensorBoard


from sklearn import  preprocessing
from sklearn.preprocessing import *

#從雲端匯入資料
DATA_ROOT = '/content/drive/MyDrive/Colab Notebooks/ntut-ml-regression-2021'
print(os.listdir(DATA_ROOT))

#匯入資料
data_train = pd.read_csv(f'{DATA_ROOT}/train-v3.csv')
data_valid = pd.read_csv(f'{DATA_ROOT}/valid-v3.csv')
data_test = pd.read_csv(f'{DATA_ROOT}/test-v3.csv')

import seaborn as sns   # 引入Seaborn

train_corr = data_train.corr(method = "pearson")[['price']].sort_values(by="price", ascending=False)
plt.subplots(figsize=(8,11))
sns.heatmap(train_corr,annot=True, vmax=1, cmap='GnBu')
#print(train_corr)

from pandas.plotting import scatter_matrix

attr = ['price','sqft_living',"grade",'sqft_above','sqft_living15']
hp= data_train[attr]
g=sns.PairGrid(hp)
g.map(sns.scatterplot)

def dataprocess(var):  
  #房屋面積跟沒有地下室面積關
  var['abo_liv'] = var['sqft_living'] - var['sqft_above']
  #是不是在地下室
  var['havebase']=0
  myindex = var[var['abo_liv'] == 0].index.tolist()
  for i in myindex:
    var.loc[i, 'havebase'] = 1
  #房間跟廁所的總和
  var['bed_sum_bat']= var['bathrooms'] + var['bedrooms']
  #房間跟廁所的差值
  var['bed_min_bat'] = var['bathrooms'] - var['bedrooms']
  #房間跟廁所的數量在面積上的關係
  var['BBR'] = (var['bathrooms'] + var['bedrooms']) / var['sqft_living']
  # 房屋面積跟沒有地下室面積關跟地方平方英尺關係
  var['abo_liv_div_lot'] = var['abo_liv'] * var['sqft_lot']
  #多少地多大客廳
  var[' howbigliving'] = var['sqft_living15'] / var['sqft_lot15']
  #豪華景觀高樓層
  var['bigview'] = var['view'] * var[ 'waterfront'] + var['floors']
  #房屋年齡
  var['age']=var['sale_yr']-var['yr_built']
  #出售前房屋整修年齡
  var['age_rnv']=0
  myindex = var[var['yr_renovated'] != 0].index.tolist()
  for i in myindex:
    var.loc[i, 'age_rnv'] = np.log1p(var.at[i, 'yr_renovated'] - var.at[i, 'yr_built'])
  myindex = var[var['yr_renovated'] > var['sale_yr']].index.tolist()
  for i in myindex:
    var.loc[i, 'age_rnv'] = 0
  
  change_data = pd.concat([var['abo_liv'],var['havebase'], var['bed_sum_bat'],var['bed_min_bat'],var['BBR'],
                var['abo_liv_div_lot'],var[' howbigliving'],var['bigview'],var['age'],var['age_rnv']],axis=1)
  return change_data

data_change=dataprocess(data_train)
data_change.head(20)

#進行數據清洗(缺失值檢缺失值檢查、重複值檢查、數據類型轉換、剔除異常值)
def get_missing_values(df):
  tatal= df.isnull().sum().sort_values(ascending=False)
  percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)
  missing_data = pd.concat([tatal,percent],axis=1 ,keys=['Total','Percent'])
  return(missing_data)
test_miss=get_missing_values(data_train)
test_miss.head

X_train = data_train.drop(['price','id','zipcode','sale_yr','sale_day','sale_month'],axis=1).values  #先將price and id 刪除
Y_train = data_train['price'].values            #只保留price

X_valid = data_valid.drop(['price','id','zipcode','sale_yr','sale_day','sale_month'],axis=1).values  #刪除行 axis=0 刪除
Y_valid = data_valid['price'].values

X_test = data_test.drop(['id','zipcode','sale_yr','sale_day','sale_month'],axis=1).values

#資料標準化        新資料=(原值-均值)/標準差
scaler = StandardScaler().fit(X_train)
X_train = scale(X_train)
X_valid = scaler.transform(X_valid)
X_test = scaler.transform(X_test)

#建模
model = Sequential()  #建立Sequential模型
model.add(Dense(100, input_dim = X_train.shape[1], kernel_initializer='normal',activation='relu'))  #激勵函數，處理非線性問題
model.add(Dense(150,  kernel_initializer='normal',activation='relu'))
model.add(Dense(200,  kernel_initializer='normal',activation='relu'))
model.add(Dense(160,  kernel_initializer='normal',activation='relu'))
model.add(Dense(100,  kernel_initializer='normal',activation='relu'))

model.add(Dense(1, kernel_initializer='normal',activation='linear'))

model.compile(loss='MAE', optimizer='adam') #預測值與真實值之間的差異，MAE=平均絕對值誤差
epochs = 100
batch_size = 20

file_name = str(epochs)+'_'+str(batch_size)
TB = TensorBoard(log_dir='lods/'+file_name, histogram_freq=0)
history = model.fit(X_train,Y_train,batch_size=batch_size, 
                    epochs=epochs,validation_data=(X_valid, Y_valid),callbacks=[TB])

losses = pd.DataFrame(model.history.history)
losses.plot()
model.summary()

#儲存
Y_predict = model.predict(X_test)
with open("final.csv","w") as f :
  f.write('id,price\n')
  for i in range(len(Y_predict)):
    f.write(str(i+1) + ',' + str(float(Y_predict[i])) + "\n")